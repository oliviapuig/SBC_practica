{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_name = 'data.json'\n",
    "pkl_name = 'casos.pkl'\n",
    "csv_name = 'casos.csv'\n",
    "carpeta = ''\n",
    "pkl_name_ll = 'llibres.pkl'\n",
    "csv_name_ll = 'llibres.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if casos.pkl exists, load it\n",
    "try:\n",
    "    casos = pd.read_pickle(carpeta+pkl_name)\n",
    "    get = False\n",
    "except:\n",
    "    get = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # URL del archivo JSON comprimido\n",
    "    url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_reviews_dedup.json.gz'\n",
    "\n",
    "    # Realizar la solicitud GET al servidor\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Descomprimir el contenido del archivo\n",
    "        with gzip.GzipFile(fileobj=response.raw) as f:\n",
    "            # Leer las primeras 500 filas del JSON\n",
    "            primeras_500_filas = [json.loads(next(f)[:-1].decode('utf-8')) for _ in range(500000)]\n",
    "\n",
    "        print(\"JSON creat.\")\n",
    "    else:\n",
    "        print(f\"Error al descargar el archivo. Código de estado: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Read eoo.json only user_id, book_id, rating\n",
    "    df = pd.DataFrame(primeras_500_filas)\n",
    "    df = df[['user_id', 'book_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot rating distribution and save to eoo/rating_distribution.png\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='rating', data=df)\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Rating Distribution')\n",
    "    plt.savefig(f'{carpeta}rating_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Give me unique users\n",
    "    unique_users = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Make a database with unique users, list of books rated and list of rating for each book\n",
    "    df_aux = pd.DataFrame(columns=['user_id', 'books', 'ratings'])\n",
    "\n",
    "    for user in unique_users:\n",
    "        # Filter by user\n",
    "        user_df = df[df['user_id'] == user]\n",
    "        # Get list of books rated by user\n",
    "        books = user_df['book_id'].tolist()\n",
    "        # Get list of ratings for each book\n",
    "        ratings = user_df['rating'].tolist()\n",
    "        # Create a dictionary with books and ratings\n",
    "        user_dict = dict(zip(books, ratings))\n",
    "        # Save user, books and ratings in df_aux using pd.concat\n",
    "        df_aux = pd.concat([df_aux, pd.DataFrame({'user_id': [user], 'books': [books], 'ratings': [ratings]})])\n",
    "\n",
    "    df_aux = df_aux.reset_index(drop=True)\n",
    "\n",
    "    print(\"Dataset joined. Unique users:\", len(df_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot how many books each user has rated and save to eoo/books_rated_before.png\n",
    "    # x: each user\n",
    "    # y: number of books rated\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel('user_id')\n",
    "    plt.ylabel('Number of books rated')\n",
    "    plt.title('Number of books rated by each user')\n",
    "    plt.plot(df_aux['user_id'], df_aux['books'].apply(lambda x: len(x)))\n",
    "    plt.savefig(f'{carpeta}books_rated_before.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    min_books = 10\n",
    "    max_books = 20\n",
    "\n",
    "    # Remove users that have rated less than 10 books and more than 50\n",
    "    df_aux = df_aux[df_aux['books'].apply(lambda x: len(x) >= min_books and len(x) <= max_books)]\n",
    "    df_aux = df_aux.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dataset filtered with users with more than {min_books} and less than {max_books} books reviewed. Unique users:\", len(df_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot how many books each user has rated and save to eoo/books_rated_after.png\n",
    "    # x: each user\n",
    "    # y: number of books rated\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel('user_id')\n",
    "    plt.ylabel('Number of books rated')\n",
    "    plt.title('Number of books rated by each user')\n",
    "    plt.plot(df_aux['user_id'], df_aux['books'].apply(lambda x: len(x)))\n",
    "    plt.savefig(f'{carpeta}books_rated_after.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # For each user get 3 last books and their ratings and put them in a new column \"llibres_recomanata\" i \"puntuacions_llibres\". Then remove the 3 books from the list of books rated by the user.\n",
    "    df_aux['llibres_recomanats'] = df_aux['books'].apply(lambda x: x[-3:])\n",
    "    df_aux['puntuacions_llibres'] = df_aux['ratings'].apply(lambda x: x[-3:])\n",
    "    df_aux['books'] = df_aux['books'].apply(lambda x: x[:-3])\n",
    "    df_aux['ratings'] = df_aux['ratings'].apply(lambda x: x[:-3])\n",
    "\n",
    "    print(\"Done creating new columns.\")\n",
    "\n",
    "    # Change \"books\" and \"ratings\" columns to \"llibres_usuari\" and \"val_llibres\"\n",
    "    df_aux = df_aux.rename(columns={'books': 'llibres_usuari', 'ratings': 'val_llibres'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    df_aux.to_pickle(pkl_name)\n",
    "    df_aux.to_csv(csv_name, index=False)\n",
    "casos = pd.read_pickle(carpeta+pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llibres = pd.read_pickle(carpeta+pkl_name_ll)\n",
    "    get = False\n",
    "except:\n",
    "    get = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # For each row, add all the books from \"llibres_usuari\" and \"llibres_recomanats\" to a set\n",
    "    set_llibres = set()\n",
    "    for index, row in casos.iterrows():\n",
    "        for llibre in row['llibres_usuari']:\n",
    "            set_llibres.add(llibre)\n",
    "        for llibre in row['llibres_recomanats']:\n",
    "            set_llibres.add(llibre)\n",
    "\n",
    "    set_llibres = list(set_llibres)\n",
    "    print(len(set_llibres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    fitxer = \"/Users/ucemarc/Downloads/goodreads_books.json\"\n",
    "    # Crear un DataFrame vacío para almacenar los libros que coincidan\n",
    "    df_llibres = pd.DataFrame(columns=['isbn', 'book_id', 'similar_books', 'average_rating', 'description', 'authors', 'isbn13', 'num_pages', 'publication_year', 'title', 'language_code'])\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with open(fitxer, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            book = json.loads(line)\n",
    "            if book['book_id'] in set_llibres:\n",
    "                # Only keep the columns \"isbn\", \"book_id\", \"similar_books\", \"average_rating\", \"similar_books\", \"description\", \"authors\", \"isbn13\", \"num_pages\", \"publication_year\", \"title\" and \"language_code\"\n",
    "                book = {k: book[k] for k in ['isbn', 'book_id', 'similar_books', 'average_rating', 'similar_books', 'description', 'authors', 'isbn13', 'num_pages', 'publication_year', 'title', 'language_code']}\n",
    "                aut = []\n",
    "                for author in book['authors']:\n",
    "                    aut.append(author['author_id'])\n",
    "                book['authors'] = aut\n",
    "                # Convert the dictionary to a DataFrame\n",
    "                book = pd.DataFrame([book], index=[0])\n",
    "                # Add the book to the DataFrame\n",
    "                df_llibres = pd.concat([df_llibres, pd.DataFrame(book, index=[0])])\n",
    "    df_llibres.to_csv(\"llibres.csv\", index=False)\n",
    "    df_llibres.to_pickle(\"llibres.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llibres = pd.read_pickle(carpeta+pkl_name_ll)\n",
    "casos = pd.read_pickle(carpeta+pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"estil_literari\": [\"realisme\", \"romanticisme\", \"naturalisme\", \"simbolisme\", \"modernisme\", \"realisme magico\", \"postmodernisme\"],\n",
    "    \"temes_especifics\": [\"amor\", \"aventura\", \"terror\", \"fantasia\", \"ciencia ficcio\", \"historica\", \"filosofica\", \"psicologica\", \"social\", \"politica\", \"religiosa\", \"erotica\", \"humoristica\", \"costumista\", \"negra\", \"realista\", \"fantastica\", \"mitologica\", \"poetica\", \"satirica\", \"biografica\", \"epica\", \"didactica\", \"teatral\", \"lirica\", \"epistolar\", \"dramatica\", \"epica\", \"didactica\", \"teatral\", \"lirica\", \"epistolar\", \"dramatica\"],\n",
    "    \"complexitat\": [\"baixa\", \"mitjana\", \"alta\"],\n",
    "    \"caracteristiques\": [\"simples\", \"complexes\"],\n",
    "    \"desenvolupament_del_personatge\": [\"baix\", \"mitja\", \"alt\"],\n",
    "    \"accio_o_reflexio\": [\"accio\", \"reflexio\"],\n",
    "    \"longitud\": [\"curta\", \"mitjana\", \"llarga\"],\n",
    "    \"epoca\": [\"actual\", \"passada\", \"futura\"],\n",
    "    \"detall_cientific\": [\"baix\", \"mitja\", \"alta\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(len)\n",
    "# Número de valores únicos (entre 2 y 4)\n",
    "num_unique_values = np.random.randint(2, 5)\n",
    "\n",
    "# Seleccionar valores únicos de forma aleatoria\n",
    "unique_values = random.sample(categories[\"estil_literari\"], num_unique_values)\n",
    "\n",
    "# Crear el vector de 10 posiciones\n",
    "vector = [random.choice(unique_values) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epoca' 'estil_literari' 'complexitat']\n"
     ]
    }
   ],
   "source": [
    "# Per cada ususari\n",
    "for index, row in casos.iterrows():\n",
    "    # Agafem entre 2 i 4 estils literaris\n",
    "    estil_literari = np.random.choice(categories[\"estil_literari\"], np.random.randint(2, 5))\n",
    "    # Agafem entre 2 i 5 temes especifics\n",
    "    temes_especifics = np.random.choice(categories[\"temes_especifics\"], np.random.randint(2, 6))\n",
    "    # Agafem entre 1 i 2 complexitats\n",
    "    complexitat = np.random.choice(categories[\"complexitat\"], np.random.randint(1, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
