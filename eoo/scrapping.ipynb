{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_name = 'data.json'\n",
    "pkl_name = 'casos.pkl'\n",
    "csv_name = 'casos.csv'\n",
    "carpeta = ''\n",
    "pkl_name_ll = 'llibres.pkl'\n",
    "csv_name_ll = 'llibres.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# np seed = 0\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if casos.pkl exists, load it\n",
    "try:\n",
    "    casos = pd.read_pickle(carpeta+pkl_name)\n",
    "    get = False\n",
    "except:\n",
    "    get = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # URL del archivo JSON comprimido\n",
    "    url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_reviews_dedup.json.gz'\n",
    "\n",
    "    # Realizar la solicitud GET al servidor\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "    if response.status_code == 200:\n",
    "        # Descomprimir el contenido del archivo\n",
    "        with gzip.GzipFile(fileobj=response.raw) as f:\n",
    "            # Leer las primeras 500 filas del JSON\n",
    "            primeras_500_filas = [json.loads(next(f)[:-1].decode('utf-8')) for _ in range(500000)]\n",
    "\n",
    "        print(\"JSON creat.\")\n",
    "    else:\n",
    "        print(f\"Error al descargar el archivo. Código de estado: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Read eoo.json only user_id, book_id, rating\n",
    "    df = pd.DataFrame(primeras_500_filas)\n",
    "    df = df[['user_id', 'book_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot rating distribution and save to eoo/rating_distribution.png\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='rating', data=df)\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Rating Distribution')\n",
    "    plt.savefig(f'{carpeta}rating_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Give me unique users\n",
    "    unique_users = df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Make a database with unique users, list of books rated and list of rating for each book\n",
    "    df_aux = pd.DataFrame(columns=['user_id', 'books', 'ratings'])\n",
    "\n",
    "    for user in unique_users:\n",
    "        # Filter by user\n",
    "        user_df = df[df['user_id'] == user]\n",
    "        # Get list of books rated by user\n",
    "        books = user_df['book_id'].tolist()\n",
    "        # Get list of ratings for each book\n",
    "        ratings = user_df['rating'].tolist()\n",
    "        # Create a dictionary with books and ratings\n",
    "        user_dict = dict(zip(books, ratings))\n",
    "        # Save user, books and ratings in df_aux using pd.concat\n",
    "        df_aux = pd.concat([df_aux, pd.DataFrame({'user_id': [user], 'books': [books], 'ratings': [ratings]})])\n",
    "\n",
    "    df_aux = df_aux.reset_index(drop=True)\n",
    "\n",
    "    print(\"Dataset joined. Unique users:\", len(df_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot how many books each user has rated and save to eoo/books_rated_before.png\n",
    "    # x: each user\n",
    "    # y: number of books rated\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel('user_id')\n",
    "    plt.ylabel('Number of books rated')\n",
    "    plt.title('Number of books rated by each user')\n",
    "    plt.plot(df_aux['user_id'], df_aux['books'].apply(lambda x: len(x)))\n",
    "    plt.savefig(f'{carpeta}books_rated_before.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    min_books = 10\n",
    "    max_books = 20\n",
    "\n",
    "    # Remove users that have rated less than 10 books and more than 50\n",
    "    df_aux = df_aux[df_aux['books'].apply(lambda x: len(x) >= min_books and len(x) <= max_books)]\n",
    "    df_aux = df_aux.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dataset filtered with users with more than {min_books} and less than {max_books} books reviewed. Unique users:\", len(df_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Plot how many books each user has rated and save to eoo/books_rated_after.png\n",
    "    # x: each user\n",
    "    # y: number of books rated\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel('user_id')\n",
    "    plt.ylabel('Number of books rated')\n",
    "    plt.title('Number of books rated by each user')\n",
    "    plt.plot(df_aux['user_id'], df_aux['books'].apply(lambda x: len(x)))\n",
    "    plt.savefig(f'{carpeta}books_rated_after.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # For each user get 3 last books and their ratings and put them in a new column \"llibres_recomanata\" i \"puntuacions_llibres\". Then remove the 3 books from the list of books rated by the user.\n",
    "    df_aux['llibres_recomanats'] = df_aux['books'].apply(lambda x: x[-3:])\n",
    "    df_aux['puntuacions_llibres'] = df_aux['ratings'].apply(lambda x: x[-3:])\n",
    "    df_aux['books'] = df_aux['books'].apply(lambda x: x[:-3])\n",
    "    df_aux['ratings'] = df_aux['ratings'].apply(lambda x: x[:-3])\n",
    "\n",
    "    print(\"Done creating new columns.\")\n",
    "\n",
    "    # Change \"books\" and \"ratings\" columns to \"llibres_usuari\" and \"val_llibres\"\n",
    "    df_aux = df_aux.rename(columns={'books': 'llibres_usuari', 'ratings': 'val_llibres'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    df_aux.to_pickle(pkl_name)\n",
    "    df_aux.to_csv(csv_name, index=False)\n",
    "casos = pd.read_pickle(carpeta+pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llibres = pd.read_pickle(carpeta+pkl_name_ll)\n",
    "    get = False\n",
    "except:\n",
    "    get = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # For each row, add all the books from \"llibres_usuari\" and \"llibres_recomanats\" to a set\n",
    "    set_llibres = set()\n",
    "    for index, row in casos.iterrows():\n",
    "        for llibre in row['llibres_usuari']:\n",
    "            set_llibres.add(llibre)\n",
    "        for llibre in row['llibres_recomanats']:\n",
    "            set_llibres.add(llibre)\n",
    "\n",
    "    set_llibres = list(set_llibres)\n",
    "    print(len(set_llibres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    fitxer = \"/Users/ucemarc/Downloads/goodreads_books.json\"\n",
    "    # Crear un DataFrame vacío para almacenar los libros que coincidan\n",
    "    df_llibres = pd.DataFrame(columns=['isbn', 'book_id', 'similar_books', 'average_rating', 'description', 'authors', 'isbn13', 'num_pages', 'publication_year', 'title', 'language_code', 'format', 'series'])\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    i = 1\n",
    "    with open(fitxer, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            book = json.loads(line)\n",
    "            if book['book_id'] in set_llibres:\n",
    "                print(i)\n",
    "                # Only keep the columns \"isbn\", \"book_id\", \"similar_books\", \"average_rating\", \"similar_books\", \"description\", \"authors\", \"isbn13\", \"num_pages\", \"publication_year\", \"title\" and \"language_code\"\n",
    "                book = {k: book[k] for k in ['isbn', 'book_id', 'similar_books', 'average_rating', 'similar_books', 'description', 'authors', 'isbn13', 'num_pages', 'publication_year', 'title', 'language_code', 'format', 'series']}\n",
    "                aut = []\n",
    "                for author in book['authors']:\n",
    "                    aut.append(author['author_id'])\n",
    "                book['authors'] = aut\n",
    "                # Convert the dictionary to a DataFrame\n",
    "                book = pd.DataFrame([book], index=[0])\n",
    "                # Add the book to the DataFrame\n",
    "                df_llibres = pd.concat([df_llibres, pd.DataFrame(book, index=[0])])\n",
    "                i += 1\n",
    "    df_llibres.to_csv(\"llibres.csv\", index=False)\n",
    "    df_llibres.to_pickle(\"llibres.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If column \"genres\" exists in llibres.pkl then get = False\n",
    "try:\n",
    "    llibres = pd.read_pickle(carpeta+pkl_name_ll)\n",
    "    llibres['genres']\n",
    "    get = False\n",
    "except:\n",
    "    get = True\n",
    "    df_llibres = pd.read_csv(carpeta+csv_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    fitxer = \"/Users/ucemarc/Downloads/goodreads_book_genres_initial.json\"\n",
    "\n",
    "    # Crear un DataFrame vacío para almacenar los libros que coincidan\n",
    "    df_genres = pd.DataFrame(columns=['book_id', 'genres'])\n",
    "\n",
    "    with open(fitxer, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            book = json.loads(line)\n",
    "            if book['book_id'] in set_llibres:\n",
    "                # Only keep the columns \"isbn\", \"book_id\", \"similar_books\", \"average_rating\", \"similar_books\", \"description\", \"authors\", \"isbn13\", \"num_pages\", \"publication_year\", \"title\" and \"language_code\"\n",
    "                book = {k: book[k] for k in ['book_id', 'genres']}\n",
    "                # Get only the keys of the dictionary\n",
    "                book['genres'] = list(book['genres'].keys())\n",
    "                # Convert the dictionary to a DataFrame\n",
    "                book = pd.DataFrame([book], index=[0])\n",
    "                # Add the book to the DataFrame\n",
    "                df_genres = pd.concat([df_genres, pd.DataFrame(book, index=[0])])\n",
    "                df_genres.to_csv(\"genres.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Merge df_llibres and df_genres on book_id\n",
    "    df_llibres['book_id'] = df_llibres['book_id'].astype(int)\n",
    "    df_genres['book_id'] = df_genres['book_id'].astype(int)\n",
    "    df_llibres= pd.merge(df_llibres, df_genres, on='book_id', how='inner')\n",
    "    df_llibres.to_csv(\"llibres.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Check how many unique genres there are\n",
    "    unique_genres = set()\n",
    "    for index, row in df_llibres.iterrows():\n",
    "        for genre in row['genres']:\n",
    "            unique_genres.add(genre)\n",
    "    print(len(unique_genres))\n",
    "    print(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Replace 'history, historical fiction, biography' to 'history'\n",
    "    df_llibres['genres'] = df_llibres['genres'].apply(lambda x: ['history' if i == 'history, historical fiction, biography' else i for i in x])\n",
    "    # Replace 'fantasy, paranormal' to 'fantasy'\n",
    "    df_llibres['genres'] = df_llibres['genres'].apply(lambda x: ['fantasy' if i == 'fantasy, paranormal' else i for i in x])\n",
    "    # Replace 'mystery, thriller, crime' to 'mystery'\n",
    "    df_llibres['genres'] = df_llibres['genres'].apply(lambda x: ['mystery' if i == 'mystery, thriller, crime' else i for i in x])\n",
    "    # Replace 'comics, graphic' to 'comics'\n",
    "    df_llibres['genres'] = df_llibres['genres'].apply(lambda x: ['comics' if i == 'comics, graphic' else i for i in x])\n",
    "    df_llibres.to_csv(carpeta+csv_name_ll, index=False)\n",
    "    df_llibres.to_pickle(carpeta+pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get:\n",
    "    # Check how many unique genres there are\n",
    "    unique_genres = set()\n",
    "    for index, row in df_llibres.iterrows():\n",
    "        for genre in row['genres']:\n",
    "            unique_genres.add(genre)\n",
    "    print(len(unique_genres))\n",
    "    print(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "llibres = pd.read_pickle(carpeta+pkl_name_ll)\n",
    "casos = pd.read_pickle(carpeta+pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"estil_literari\": [\"realisme\", \"romanticisme\", \"naturalisme\", \"simbolisme\", \"modernisme\", \"realisme magico\", \"postmodernisme\"],\n",
    "    \"complexitat\": [\"baixa\", \"mitjana\", \"alta\"],\n",
    "    \"caracteristiques\": [\"simples\", \"complexes\"],\n",
    "    \"desenvolupament_del_personatge\": [\"baix\", \"mitja\", \"alt\"],\n",
    "    \"accio_o_reflexio\": [\"accio\", \"reflexio\"],\n",
    "    \"epoca\": [\"actual\", \"passada\", \"futura\"],\n",
    "    \"detall_cientific\": [\"baix\", \"mitja\", \"alta\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(length1, length2, unique_min, unique_max, categorie):\n",
    "    # Número de valores únicos (entre 2 y 4)\n",
    "    num_unique_values = np.random.randint(unique_min, unique_max)\n",
    "\n",
    "    # Seleccionar valores únicos de forma aleatoria\n",
    "    unique_values = np.random.choice(categories[categorie], size=num_unique_values, replace=False)\n",
    "\n",
    "    # Crear el vector de 10 posiciones\n",
    "    vector1 = [np.random.choice(unique_values) for _ in range(length1)]\n",
    "    vector2 = [np.random.choice(unique_values) for _ in range(length2)]\n",
    "    return vector1, vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funció auxiliar per actualitzar els diccionaris\n",
    "def actualitzar_diccionaris(llibre_id, valor, diccionari):\n",
    "    if valor in diccionari[llibre_id]:\n",
    "        diccionari[llibre_id][valor] += 1\n",
    "    else:\n",
    "        diccionari[llibre_id][valor] = 1\n",
    "\n",
    "# Inicialització de diccionaris per a cada atribut\n",
    "estil_literari = [{} for _ in range(len(llibres))]\n",
    "complexitat = [{} for _ in range(len(llibres))]\n",
    "caracteristiques = [{} for _ in range(len(llibres))]\n",
    "desenvolupament_del_personatge = [{} for _ in range(len(llibres))]\n",
    "accio_o_reflexio = [{} for _ in range(len(llibres))]\n",
    "epoca = [{} for _ in range(len(llibres))]\n",
    "detall_cientific = [{} for _ in range(len(llibres))]\n",
    "\n",
    "for index, row in casos.iterrows():\n",
    "    len_llibres_usuari = len(row['llibres_usuari'])\n",
    "    len_llibres_recomanats = len(row['llibres_recomanats'])\n",
    "    estil_literari1, estil_literari2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 2, 4, \"estil_literari\")\n",
    "    complexitat1, complexitat2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 3, \"complexitat\")\n",
    "    caracteristiques1, caracteristiques2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 3, \"caracteristiques\")\n",
    "    desenvolupament_del_personatge1, desenvolupament_del_personatge2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 3, \"desenvolupament_del_personatge\")\n",
    "    accio_o_reflexio1, accio_o_reflexio2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 2, \"accio_o_reflexio\")\n",
    "    epoca1, epoca2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 3, \"epoca\")\n",
    "    detall_cientific1, detall_cientific2 = make_vector(len_llibres_usuari, len_llibres_recomanats, 1, 3, \"detall_cientific\")\n",
    "\n",
    "    for i in range(len_llibres_usuari):\n",
    "        llibre_id_usuari = llibres[llibres[\"book_id\"] == int(row['llibres_usuari'][i])].index[0]\n",
    "        actualitzar_diccionaris(llibre_id_usuari, estil_literari1[i], estil_literari)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, complexitat1[i], complexitat)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, caracteristiques1[i], caracteristiques)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, desenvolupament_del_personatge1[i], desenvolupament_del_personatge)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, accio_o_reflexio1[i], accio_o_reflexio)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, epoca1[i], epoca)\n",
    "        actualitzar_diccionaris(llibre_id_usuari, detall_cientific1[i], detall_cientific)\n",
    "\n",
    "    for i in range(len_llibres_recomanats):\n",
    "        llibre_id_recomanat = llibres[llibres[\"book_id\"] == int(row['llibres_recomanats'][i])].index[0]\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, estil_literari2[i], estil_literari)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, complexitat2[i], complexitat)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, caracteristiques2[i], caracteristiques)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, desenvolupament_del_personatge2[i], desenvolupament_del_personatge)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, accio_o_reflexio2[i], accio_o_reflexio)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, epoca2[i], epoca)\n",
    "        actualitzar_diccionaris(llibre_id_recomanat, detall_cientific2[i], detall_cientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the most voted value for each book\n",
    "for i in range(len(llibres)):\n",
    "    if len(estil_literari[i]) > 0:\n",
    "        estil_literari[i] = max(estil_literari[i], key=estil_literari[i].get)\n",
    "    if len(complexitat[i]) > 0:\n",
    "        complexitat[i] = max(complexitat[i], key=complexitat[i].get)\n",
    "    if len(caracteristiques[i]) > 0:\n",
    "        caracteristiques[i] = max(caracteristiques[i], key=caracteristiques[i].get)\n",
    "    if len(desenvolupament_del_personatge[i]) > 0:\n",
    "        desenvolupament_del_personatge[i] = max(desenvolupament_del_personatge[i], key=desenvolupament_del_personatge[i].get)\n",
    "    if len(accio_o_reflexio[i]) > 0:\n",
    "        accio_o_reflexio[i] = max(accio_o_reflexio[i], key=accio_o_reflexio[i].get)\n",
    "    if len(epoca[i]) > 0:\n",
    "        epoca[i] = max(epoca[i], key=epoca[i].get)\n",
    "    if len(detall_cientific[i]) > 0:\n",
    "        detall_cientific[i] = max(detall_cientific[i], key=detall_cientific[i].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15666\n",
      "15666\n"
     ]
    }
   ],
   "source": [
    "print(len(estil_literari))\n",
    "print(len(llibres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afegir les noves columnes al DataFrame\n",
    "llibres[\"estil_literari\"] = estil_literari\n",
    "llibres[\"complexitat\"] = complexitat\n",
    "llibres[\"caracteristiques\"] = caracteristiques\n",
    "llibres[\"desenvolupament_del_personatge\"] = desenvolupament_del_personatge\n",
    "llibres[\"accio_o_reflexio\"] = accio_o_reflexio\n",
    "llibres[\"epoca\"] = epoca\n",
    "llibres[\"detall_cientific\"] = detall_cientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "llibres.to_pickle(pkl_name_ll)\n",
    "llibres.to_csv(csv_name_ll, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓ PER ELIMINAR DE SIMILARS AQUELLS LLIBRES QUE NO ESTAN A LA BASE DE DADES\n",
    "# Carregar les dades del CSV\n",
    "df = pd.read_csv(csv_name_ll)\n",
    "\n",
    "# Funció per convertir la cadena de la llista en una llista real i netejar-la\n",
    "def neteja_similars(similars, ids_valids):\n",
    "    # Convertir la cadena a una llista\n",
    "    similars_list = similars.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    # Mantenir només els IDs que estan presents en ids_valids\n",
    "    return [id for id in similars_list if id in ids_valids]\n",
    "\n",
    "# Obtenir els book_id com a conjunt per a una cerca més ràpida\n",
    "ids_valids = set(df['book_id'].astype(str))\n",
    "df['similar_books'] = df['similar_books'].apply(lambda x: neteja_similars(x, ids_valids))\n",
    "\n",
    "# Funció per assignar 'noisbn'\n",
    "def assigna_noisbn(valor):\n",
    "    if pd.isna(valor) or valor == 'NaN':\n",
    "        return 'noisbn'\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "# Aplicar la funció a les columnes isbn i isbn13\n",
    "df['isbn'] = df['isbn'].apply(assigna_noisbn)\n",
    "df['isbn13'] = df['isbn13'].apply(assigna_noisbn)\n",
    "\n",
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ebook' 'tapa blanda' 'audio' 'tapa dura']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(pkl_name_ll)\n",
    "# imprimir les diferents categories de \"format\"\n",
    "print(df['format'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificar les diferents categories de audio\n",
    "df['format'] = df['format'].apply(lambda x: 'audio' if x in ['Audible Audio', 'Audio CD', 'Audio Cassette', 'Audio', 'Audiobook', 'audio cd', 'MP3 CD'] else x)\n",
    "# Unificar les diferents categories de ebook\n",
    "df['format'] = df['format'].apply(lambda x: 'ebook' if x in ['ebook', 'Kindle Edition', 'HTML', 'Kindle', 'chapbook/ebook', 'Serialized Digital Download'] else x)\n",
    "# Unificar les diferents categories de paper\n",
    "df['format'] = df['format'].apply(lambda x: 'tapa blanda' if x in ['Paperback', 'Mass Market Paperback', 'paper', 'Trade Paperback', 'pocket', 'Softcover', 'Trade paperback', 'Paper Back', 'Perfect Paperback', 'paperback', 'Trade Paper', 'Paberback', 'Softcover with Flap', 'Tapa blanda con solapas'] else x)\n",
    "# Unificar les diferents categories de hardcover\n",
    "df['format'] = df['format'].apply(lambda x: 'tapa dura' if x in ['Hardcover', 'Board book', 'Board Book', 'Hardback', 'hardcover', 'issue', 'Broche', 'Klappenbroschur', 'Nook', 'Library Binding', 'Gebunden', 'Wen Ku', 'Leather Bound', 'Musc. Supplies', 'Podiobook', 'Brossura', 'Nook Book', 'Spiral-bound', 'Novelty Book', 'Glf `dy,', 'Misc. Supplies', 'Broschiert', 'Unknown Binding'] else x)\n",
    "# Unificar les diferents categories de comic\n",
    "df['format'] = df['format'].apply(lambda x: 'tapa blanda' if x in ['comics', 'Thirteen interactive chapters.', 'Graphic Novel', 'Digital comic', 'Comic Book'] else x)\n",
    "# Poner los nan a las otras categorias siguiendo la distribución de las categorias actuales\n",
    "df['format'] = df['format'].apply(lambda x: np.random.choice(['tapa blanda', 'tapa dura', 'ebook']) if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ebook' 'tapa blanda' 'audio' 'tapa dura']\n",
      "format\n",
      "tapa blanda    7800\n",
      "tapa dura      4913\n",
      "ebook          2790\n",
      "audio           163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# imprimir les diferents categories de \"format\"\n",
    "print(df['format'].unique())\n",
    "# Print how many books there are for each format\n",
    "print(df['format'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos los valores menores a 1.5 en average_rating a la media\n",
    "df['average_rating'] = df['average_rating'].apply(lambda x: np.random.uniform(1.5, 5) if x < 1.5 else x)\n",
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pages\n",
      "336     865\n",
      "339     600\n",
      "331     375\n",
      "329     334\n",
      "320     300\n",
      "       ... \n",
      "1153      1\n",
      "39        1\n",
      "1607      1\n",
      "1011      1\n",
      "931       1\n",
      "Name: count, Length: 940, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check value count for num_pages including nan\n",
    "df = pd.read_pickle(pkl_name_ll)\n",
    "print(df['num_pages'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def obtener_info_libro(isbn):\n",
    "    base_url = \"https://openlibrary.org/api/books\"\n",
    "    params = {\n",
    "        \"bibkeys\": f\"ISBN:{isbn}\",\n",
    "        \"format\": \"json\",\n",
    "        \"jscmd\": \"data\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if f\"ISBN:{isbn}\" in data:\n",
    "            book_info = data[f\"ISBN:{isbn}\"]\n",
    "            return book_info  # Devuelve todos los campos disponibles\n",
    "        else:\n",
    "            return \"No se encontró información para ese ISBN.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Para los libros que no tienen num_pages, obtener el número de páginas de OpenLibrary\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row['num_pages']) or pd.isna(row['publication_year']):\n",
    "        isbn = row['isbn13']\n",
    "        if isbn != 'noisbn':\n",
    "            info_libro = obtener_info_libro(isbn)\n",
    "            if info_libro != \"No se encontró información para ese ISBN.\":\n",
    "                if pd.isna(row['num_pages']):\n",
    "                    try:\n",
    "                        num_pages = int(info_libro['number_of_pages'])\n",
    "                        df.at[index, 'num_pages'] = num_pages\n",
    "                        print(f\"ISBN: {isbn} - Pages: {num_pages}\")\n",
    "                    except:\n",
    "                        print(f\"ISBN: {isbn} - No info\")\n",
    "                if pd.isna(row['publication_year']):\n",
    "                    try:\n",
    "                        publication_year = int(info_libro['publish_date'])\n",
    "                        df.at[index, 'publication_year'] = publication_year\n",
    "                        print(f\"ISBN: {isbn} - pub_year: {publication_year}\")\n",
    "                    except:\n",
    "                        print(f\"ISBN: {isbn} - No info\")\n",
    "            else:\n",
    "                print(f\"ISBN: {isbn} - No info 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si algun libro tiene menos de 10 páginas y no es audio, ponerle audio\n",
    "for index, row in df.iterrows():\n",
    "    if row['num_pages'] <= 10 and row['format'] != 'audio':\n",
    "        df.at[index, 'format'] = 'audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el numero de paginas es nan, ponerle la media de los libros del mismo estilo literario\n",
    "ll = df.groupby('estil_literari')['num_pages'].apply(lambda x: x.fillna(x.mean()).astype(int))\n",
    "df['num_pages'] = ll.to_list()\n",
    "df['num_pages'] = df['num_pages'].astype(int)\n",
    "# Si el publication_year es nan, ponerle la media de los libros del mismo estilo literario\n",
    "ll = df.groupby('estil_literari')['publication_year'].apply(lambda x: x.fillna(x.mean()).astype(int))\n",
    "df['publication_year'] = ll.to_list()\n",
    "df['publication_year'] = df['publication_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb Celda 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mseries\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(get_numbers)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb Celda 44\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_numbers\u001b[39m(series):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pd\u001b[39m.\u001b[39misna(series):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         series \u001b[39m=\u001b[39m series\u001b[39m.\u001b[39;49mstrip(\u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         series \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(i\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m series]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m series\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# SERIES\n",
    "# Coger los numeros y ponerlos en listas de la variable series\n",
    "df['series'] = df['series'].apply(lambda x: np.nan if x == '[]' else x)\n",
    "def get_numbers(series):\n",
    "    if not pd.isna(series):\n",
    "        series = series.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "        series = [int(i.split(\" \")[-1]) for i in series]\n",
    "        return series\n",
    "    else:\n",
    "        return np.nan\n",
    "df['series'] = df['series'].apply(get_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb Celda 45\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get first number of series\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mseries\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m x \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m np\u001b[39m.\u001b[39;49mnan \u001b[39melse\u001b[39;49;00m np\u001b[39m.\u001b[39;49mnan)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb Celda 45\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get first number of series\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ucemarc/Documents/GitHub/SBC_practica/eoo/scrapping.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mnan \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mnan)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Get first number of series\n",
    "df['series'] = df['series'].apply(lambda x: x[0] if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['series'] = df['series'].astype(str)\n",
    "dic_series = df['series'].value_counts().to_dict()\n",
    "# put tu nan all series that have 1 book\n",
    "df['series'] = df['series'].apply(lambda x: np.nan if dic_series[x] <= 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nan': 14604,\n",
       " '735877.0': 9,\n",
       " '384360.0': 8,\n",
       " '895759.0': 6,\n",
       " '157411.0': 6,\n",
       " '167817.0': 6,\n",
       " '273035.0': 6,\n",
       " '747511.0': 5,\n",
       " '833252.0': 5,\n",
       " '162522.0': 5,\n",
       " '558803.0': 5,\n",
       " '158565.0': 5,\n",
       " '411528.0': 5,\n",
       " '205946.0': 5,\n",
       " '195203.0': 5,\n",
       " '1055430.0': 5,\n",
       " '161525.0': 5,\n",
       " '157478.0': 5}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_series = df['series'].value_counts().to_dict()\n",
    "dic_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'book_id', 'similar_books', 'average_rating', 'description',\n",
       "       'authors', 'isbn13', 'num_pages', 'publication_year', 'title',\n",
       "       'language_code', 'format', 'series', 'genres', 'estil_literari',\n",
       "       'complexitat', 'caracteristiques', 'desenvolupament_del_personatge',\n",
       "       'accio_o_reflexio', 'epoca', 'detall_cientific'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies for categorical variables and drop the original columns\n",
    "df = pd.read_pickle(pkl_name_ll)\n",
    "llibres_dummies = pd.get_dummies(df, columns=['language_code', 'format', 'series', 'estil_literari', 'complexitat', 'caracteristiques', 'desenvolupament_del_personatge', 'accio_o_reflexio', 'epoca', 'detall_cientific'])\n",
    "# Eliminar totes les columnes que no siguin booleanes\n",
    "for column in llibres_dummies.columns:\n",
    "    if llibres_dummies[column].dtype != bool:\n",
    "        llibres_dummies = llibres_dummies.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_code_amh</th>\n",
       "      <th>language_code_ara</th>\n",
       "      <th>language_code_ben</th>\n",
       "      <th>language_code_cze</th>\n",
       "      <th>language_code_dan</th>\n",
       "      <th>language_code_en</th>\n",
       "      <th>language_code_fil</th>\n",
       "      <th>language_code_fin</th>\n",
       "      <th>language_code_fre</th>\n",
       "      <th>language_code_ger</th>\n",
       "      <th>...</th>\n",
       "      <th>desenvolupament_del_personatge_baix</th>\n",
       "      <th>desenvolupament_del_personatge_mitja</th>\n",
       "      <th>accio_o_reflexio_accio</th>\n",
       "      <th>accio_o_reflexio_reflexio</th>\n",
       "      <th>epoca_actual</th>\n",
       "      <th>epoca_futura</th>\n",
       "      <th>epoca_passada</th>\n",
       "      <th>detall_cientific_alta</th>\n",
       "      <th>detall_cientific_baix</th>\n",
       "      <th>detall_cientific_mitja</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15662</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15666 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language_code_amh  language_code_ara  language_code_ben  \\\n",
       "0                  False              False              False   \n",
       "1                  False              False              False   \n",
       "2                  False              False              False   \n",
       "3                  False              False              False   \n",
       "4                  False              False              False   \n",
       "...                  ...                ...                ...   \n",
       "15661              False              False              False   \n",
       "15662              False              False              False   \n",
       "15663              False              False              False   \n",
       "15664              False              False              False   \n",
       "15665              False              False              False   \n",
       "\n",
       "       language_code_cze  language_code_dan  language_code_en  \\\n",
       "0                  False              False             False   \n",
       "1                  False              False              True   \n",
       "2                  False              False              True   \n",
       "3                  False              False              True   \n",
       "4                  False              False              True   \n",
       "...                  ...                ...               ...   \n",
       "15661              False              False             False   \n",
       "15662              False              False              True   \n",
       "15663              False              False              True   \n",
       "15664              False              False             False   \n",
       "15665              False              False             False   \n",
       "\n",
       "       language_code_fil  language_code_fin  language_code_fre  \\\n",
       "0                  False              False              False   \n",
       "1                  False              False              False   \n",
       "2                  False              False              False   \n",
       "3                  False              False              False   \n",
       "4                  False              False              False   \n",
       "...                  ...                ...                ...   \n",
       "15661              False              False              False   \n",
       "15662              False              False              False   \n",
       "15663              False              False              False   \n",
       "15664              False              False              False   \n",
       "15665              False              False              False   \n",
       "\n",
       "       language_code_ger  ...  desenvolupament_del_personatge_baix  \\\n",
       "0                  False  ...                                False   \n",
       "1                  False  ...                                 True   \n",
       "2                  False  ...                                 True   \n",
       "3                  False  ...                                False   \n",
       "4                  False  ...                                 True   \n",
       "...                  ...  ...                                  ...   \n",
       "15661              False  ...                                 True   \n",
       "15662              False  ...                                False   \n",
       "15663              False  ...                                False   \n",
       "15664              False  ...                                False   \n",
       "15665              False  ...                                 True   \n",
       "\n",
       "       desenvolupament_del_personatge_mitja  accio_o_reflexio_accio  \\\n",
       "0                                      True                   False   \n",
       "1                                     False                   False   \n",
       "2                                     False                    True   \n",
       "3                                     False                   False   \n",
       "4                                     False                    True   \n",
       "...                                     ...                     ...   \n",
       "15661                                 False                   False   \n",
       "15662                                 False                    True   \n",
       "15663                                  True                    True   \n",
       "15664                                  True                    True   \n",
       "15665                                 False                   False   \n",
       "\n",
       "       accio_o_reflexio_reflexio  epoca_actual  epoca_futura  epoca_passada  \\\n",
       "0                           True          True         False          False   \n",
       "1                           True          True         False          False   \n",
       "2                          False          True         False          False   \n",
       "3                           True          True         False          False   \n",
       "4                          False         False          True          False   \n",
       "...                          ...           ...           ...            ...   \n",
       "15661                       True         False          True          False   \n",
       "15662                      False         False          True          False   \n",
       "15663                      False         False         False           True   \n",
       "15664                      False         False         False           True   \n",
       "15665                       True         False          True          False   \n",
       "\n",
       "       detall_cientific_alta  detall_cientific_baix  detall_cientific_mitja  \n",
       "0                      False                   True                   False  \n",
       "1                       True                  False                   False  \n",
       "2                      False                  False                    True  \n",
       "3                      False                   True                   False  \n",
       "4                      False                  False                    True  \n",
       "...                      ...                    ...                     ...  \n",
       "15661                   True                  False                   False  \n",
       "15662                  False                   True                   False  \n",
       "15663                   True                  False                   False  \n",
       "15664                   True                  False                   False  \n",
       "15665                   True                  False                   False  \n",
       "\n",
       "[15666 rows x 83 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llibres_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(vector, min_ant = 0, max_ant = 5, min_nou = 0, max_nou = 1):\n",
    "    \"\"\"\n",
    "    Passar de una valoracio [0-5] a una puntuació [-1-1]\n",
    "    \"\"\"\n",
    "    if isinstance(vector, int):\n",
    "        vector = np.array([vector])\n",
    "    if vector.shape[0] > 1:\n",
    "        min_ant = min(vector)\n",
    "        #max_ant = max(vector)\n",
    "    escalador = MinMaxScaler(feature_range=(min_nou, max_nou))\n",
    "    escalador.fit([[min_ant], [max_ant]])\n",
    "    return escalador.transform(vector.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_av_rating = scale(df['average_rating'].to_numpy())\n",
    "scaled_num_pages = scale(df['num_pages'].to_numpy(), min_ant=0, max_ant=900)\n",
    "# All numbers > 1 in scaled_num_pages are set to 1\n",
    "scaled_num_pages = np.where(scaled_num_pages > 1, 1, scaled_num_pages)\n",
    "scaled_av_rating = np.round(scaled_av_rating, 2)\n",
    "scaled_num_pages = np.round(scaled_num_pages, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "llibres_dummies['average_rating'] = scaled_av_rating\n",
    "llibres_dummies['num_pages'] = scaled_num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make vector of each book and add it to the dataframe\n",
    "vectors = np.array(llibres_dummies).astype(float)\n",
    "df[\"vector\"] = vectors.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_name_ll, index=False)\n",
    "df.to_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ger user vectors\n",
    "casos = pd.read_pickle(pkl_name)\n",
    "llibres = pd.read_pickle(pkl_name_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(vector, min_ant = 0, max_ant = 5, min_nou = -1, max_nou = 1):\n",
    "    \"\"\"\n",
    "    Passar de una valoracio [0-5] a una puntuació [-1-1]\n",
    "    \"\"\"\n",
    "    if isinstance(vector, int):\n",
    "        vector = np.array([vector])\n",
    "    if vector.shape[0] > 1:\n",
    "        min_ant = min(vector)\n",
    "        max_ant = max(vector)\n",
    "    escalador = MinMaxScaler(feature_range=(min_nou, max_nou))\n",
    "    escalador.fit([[min_ant], [max_ant]])\n",
    "    return escalador.transform(vector.reshape(-1, 1)).flatten()\n",
    "\n",
    "def get_attributes(llibres_usuari, val_llibres):\n",
    "    \"\"\"\n",
    "    Aconseguir el vector d'atributs d'usuari a partir dels llibres que ha llegit\n",
    "    \"\"\"\n",
    "    len_vector = len(llibres[\"vector\"].iloc[0])\n",
    "    vector_usuari = np.zeros(len_vector)\n",
    "    for ll, val in zip(llibres_usuari, val_llibres):\n",
    "        vector_usuari += np.array(llibres[llibres[\"book_id\"] == int(ll)][\"vector\"].iloc[0]) * scale(val)\n",
    "    vector_usuari = scale(vector_usuari)\n",
    "    #print(\"Vector usuari escalat: \", vector_usuari)\n",
    "\n",
    "    # Si hay vectores con valores entre -0.01 y 0.01, los ponemos a 0\n",
    "    for i in range(len(vector_usuari)):\n",
    "        if vector_usuari[i] < 0.01 and vector_usuari[i] > -0.01:\n",
    "            vector_usuari[i] = 0\n",
    "\n",
    "    return np.round(vector_usuari, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for index, row in casos.iterrows():\n",
    "    vector_usuari = get_attributes(row['llibres_usuari'], row['val_llibres'])\n",
    "    vectors.append(vector_usuari)\n",
    "casos[\"vector_usuari\"] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos.to_csv(csv_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
